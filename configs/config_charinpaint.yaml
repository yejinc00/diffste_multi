# train on combination of all datas
data:
  target: "src.trainers.WrappedDataModule"
  batch_size: 4
  scene_data: ocr-dataset/
  synth_data: ocr-dataset/synth/
  train:
    size: 256
    max_num: 800 # diffly choose this number
    augconf:
      synth:
        center: 0.1
        pad: false
      scene:
        expand_mask:
          center_mask: 0.6
          additional_mask: 0.4
        crop:
          mask_image_ratio: 15
        rotate:
          cat_prob: [1, 0, 0]
          angle_list: [-15, -30, -45, -60, -90, 15, 30, 45, 60, 90]
          rotate_range: 90

    dataconfs:
      Synthtiger:
        type: synth
        label_path: ${data.synth_data}/data.csv
        image_dir: ${data.synth_data}/
        style_mode: same-same
        use_textbbox: false
        style_dropout: [0.5, 0.5]
        rand_mask_text: true

  validation:
    size: 256
    # max_num: 200 # diffly choose this number
    augconf:
      synth:
        center: 1.
        pad: false
      scene:
        expand_mask:
          center_mask: 0.
          additional_mask: 0.
        crop:
          mask_image_ratio: 30
        rotate:
          cat_prob: [1, 0, 0]
          angle_list: [-15, -30, -45, -60, -90, 15, 30, 45, 60, 90]
          rotate_range: 90

    dataconfs:
      Synthtiger:
        type: synth
        label_path: ${data.synth_data}/data.csv
        image_dir: ${data.synth_data}/
        style_mode: same-same
        use_textbbox: false
        style_dropout: [0.5, 0.5]
        rand_mask_text: true

model:
  source: raw
  target: "src.trainers.CharInpaintModelWrapper"
  pretrained_model_path: runwayml/stable-diffusion-inpainting
  loss_type: MaskMSELoss
  loss_alpha: 5
  base_learning_rate: 5.0e-5
  precision: 16
  weight_decay: 0.0
  adam_epsilon: 1.0e-8
  freeze_char_embedder: false
  optimize_vae: false
  vae:

  tokenizer:
    model_max_length: 20
  char_tokenizer:
    pretrained_path: checkpoints/chartokenizer
    pad_token: " "
    unk_token: " "
    model_max_length: 20
  char_embedder:
    vocab_size: 147 # by default
    embedding_dim: 32
    max_length: 20
    padding_idx: 0
    attention_head_dim: 2
  unet:
    attention_head_dim: { "text": 8, "char": 2 }
    cross_attention_dim: { "text": 768, "char": 32 }
  noise_scheduler: diffusers.DDIMScheduler

lightning:
  logger:
  callbacks:
    checkpoint_callback:
      params:
        save_top_k: -1
    image_logger:
      target: "src.trainers.CharInpaintImageLogger"
      params:
        # train_batch_frequency: 2400
        # valid_batch_frequency: 500
        train_batch_frequency: 2
        valid_batch_frequency: 2
        disable_wandb: true
        generation_kwargs:
          num_inference_steps: 30
          num_sample_per_image: 3
          guidance_scale: 7.5
          seed: 42

    # NOTE: Download pretrained ABINet model from https://github.com/FangShancheng/ABINet.git and
    #       put model checkpoints in checkpoints/abinet to use this callback
    # ocracc_logger:
    #   target: "src.trainers.OCRAccLogger"
    #   params:
    #     train_eval_conf:
    #       size: 256
    #       augconf: ${data.validation.augconf}
    #       max_num: 5
    #       dataconfs:
    #         TextOCR:
    #           type: scene
    #           label_path: ${data.scene_data}/TextOCR/TextOCR_0.1_train.json
    #           image_dir: ${data.scene_data}/TextOCR/train_images/
    #           len_counter:
    #             eachnum: 10

    #     val_eval_conf:
    #       size: 256
    #       augconf: ${data.validation.augconf}
    #       max_num: 5
    #       dataconfs:
    #         TextOCR:
    #           type: scene
    #           label_path: ${data.scene_data}/TextOCR/TextOCR_0.1_val.json
    #           image_dir: ${data.scene_data}/TextOCR/train_images/
    #           max_num: 1000
    #     base_log_dir: ${base_log_dir}/ocrlogs # will be set in code

  trainer:
    accelerator: gpu
    devices: [0]
    strategy: ddp
    amp_backend: native
    log_every_n_steps: 16 # this is global step
    precision: 16
    max_epochs: 15
    check_val_every_n_epoch: 1
    accumulate_grad_batches: 8
    gradient_clip_val: 3.
    gradient_clip_algorithm: norm
    benchmark: true
